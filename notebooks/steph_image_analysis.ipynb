{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sasha/PycharmProjects/OpticalPooledScreens/projects/steph\n"
     ]
    }
   ],
   "source": [
    "import ops\n",
    "from ops.imports_ipython import *\n",
    "\n",
    "# runs example from repository directory\n",
    "home = os.path.dirname(os.path.dirname(ops.__file__))\n",
    "os.chdir(os.path.join(home, 'projects', 'steph'))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "WILDCARDS = dict(well=3, tile=1) # change these to change the well and tile that you want to analyze\n",
    "CYCLES = 11 # number of cycles\n",
    "\n",
    "# image processing thresholds and expected values\n",
    "THRESHOLD_READS = 50\n",
    "THRESHOLD_DAPI = 2000\n",
    "THRESHOLD_CELL = 2500\n",
    "NUCLEUS_AREA = 40, 400\n",
    "\n",
    "SBS_CYCLES = range(1, CYCLES + 1)\n",
    "\n",
    "# color of bases\n",
    "# lut = \"lookup table\", used to map one color to another like a filter\n",
    "LUTS = [\n",
    "    ops.io.GRAY,\n",
    "    ops.io.GREEN,\n",
    "    ops.io.RED,\n",
    "    ops.io.MAGENTA,\n",
    "    ops.io.CYAN\n",
    "]\n",
    "\n",
    "# for formatting tif images when they are saved?\n",
    "DISPLAY_RANGES = [\n",
    "    [500, 15000],\n",
    "    [100, 10000],\n",
    "    [100, 20000],\n",
    "    [100, 8000],\n",
    "    [100, 6000]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "barcodes = pd.read_csv('design.csv').drop(columns=\"sgRNA\") # list of barcodes along with which gene they target\n",
    "barcodes[\"barcode\"] = barcodes[\"barcode\"].apply(lambda x: x[:CYCLES])\n",
    "barcode_set = set(barcodes[\"barcode\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['data/10x_Cycle1_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle2_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle3_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle4_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle5_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle6_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle7_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle8_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0393.ome.tif', 'data/10x_Cycle9_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle10_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif', 'data/10x_Cycle11_Well3_Point3_0001_ChannelDAPI,G-ISS,T-ISS,A-ISS,C-ISS_Seq0785.ome.tif']\n"
     ]
    }
   ],
   "source": [
    "# find sbs images and print paths\n",
    "search = f'data/10x_Cycle*_Well{WILDCARDS[\"well\"]}_Point3_{str(WILDCARDS[\"tile\"]).rjust(4, \"0\")}*.ome.tif'\n",
    "input_files = natsorted(glob(search))\n",
    "print(len(input_files))\n",
    "print(input_files)\n",
    "# used to format output filenames\n",
    "description = {'mag': \"10X\", \"well\": WILDCARDS[\"well\"], 'tile': WILDCARDS['tile'], 'subdir': f'process_ipynb/tile{WILDCARDS[\"tile\"]}', 'ext': 'tif'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "data = np.array([read(f) for f in input_files])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "data, x_offsets, y_offsets = Snake._align_SBS(data, method=\"SBS_mean\") # rigid alignment of sequencing cycles and channels.\n",
    "save(name(description, tag='aligned'), data, display_ranges=DISPLAY_RANGES, luts=LUTS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "loged = Snake._transform_log(data, skip_index=0) # apply Laplacian-of-Gaussian filter from scipy.ndimage.\n",
    "# save(name(description, tag='log'), loged, display_ranges=DISPLAY_RANGES, luts=LUTS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "maxed = Snake._max_filter(loged, 3, remove_index=0) # apply a maximum filter in a window of `width`. Conventionally operates on Laplacian-of-Gaussian filtered SBS data, dilating sequencing channels to compensate for single-pixel alignment error.\n",
    "save(name(description, tag='maxed'), maxed, display_ranges=DISPLAY_RANGES[1:], luts=LUTS[1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "std = Snake._compute_std(loged, remove_index=0) # use standard deviation over cycles, followed by mean across channels to estimate sequencing read locations.\n",
    "# save(name(description, tag='std'), std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "peaks = Snake._find_peaks(std) # where are the spots\n",
    "# save(name(description, tag='peaks'), peaks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### segment nuclei and cells"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "# Find nuclei from DAPI (fluorescent stain)\n",
    "# change first argument if DAPI staining is only done for a certain cycle, eg. 11th cycle would be data[10]\n",
    "nuclei = Snake._segment_nuclei(data[0], THRESHOLD_DAPI,\n",
    " area_min=NUCLEUS_AREA[0], area_max=NUCLEUS_AREA[1])\n",
    "\n",
    "save(name(description, tag='nuclei'), nuclei, compress=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "cells = Snake._segment_cells(data[0], nuclei, THRESHOLD_CELL) # Matches cell labels to nuclei labels.\n",
    "save(name(description, tag='cells'), cells, compress=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### extract base intensity, call reads, assign to cells"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "# Find the signal intensity from `maxed` at each point in `peaks` above `threshold_peaks`.\n",
    "df_bases = Snake._extract_bases(maxed, peaks, cells,\n",
    "                        THRESHOLD_READS, wildcards=WILDCARDS)\n",
    "# df_bases.to_csv(name(description, tag='bases', ext='csv'), index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "df_reads = Snake._call_reads(df_bases, peaks=peaks) # call reads by compensating for channel cross-talk and calling the base with the highest corrected intensity for each cycle. Q = quality?\n",
    "filename = name(description, tag='reads', ext='csv')\n",
    "# df_reads.to_csv(filename, index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "# read from csv to match numerical precision of snakemake pipeline\n",
    "df_reads = pd.read_csv(filename) \n",
    "df_cells = Snake._call_cells(df_reads) # gets the two most-common barcode reads for each cell.\n",
    "df_cells.to_csv(name(description, tag='cells', ext='csv'), index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### annotated SBS images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "# last channel annotates base calls\n",
    "annotate_luts = LUTS + [ops.annotate.GRMC, ops.io.GRAY]\n",
    "annotate_display_ranges = [(a / 4, b / 4) for a,b in DISPLAY_RANGES] + [(0, 4)]\n",
    "annotate_SBS = Snake._annotate_SBS(log=loged, df_reads=df_reads)\n",
    "\n",
    "save(name(description, tag='annotate_SBS'), annotate_SBS,\n",
    "     display_ranges=annotate_display_ranges, luts=annotate_luts, compress=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### further analysis :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CTCAACCACTT', 9), ('TTAGCCGGATG', 9), ('GGGCCAAGAAT', 8), ('TCACAGTTTTC', 6), ('ACCATTAGGCC', 6), ('AACATGGCACT', 6), ('GAAGAAGGATG', 6), ('AGCTTACAATA', 6), ('TCTTTCCAACT', 5), ('GTTGCCAGCTT', 5), ('GACCCCTAGAT', 5), ('GGGCATGAGAT', 5), ('AGAGAATTCTG', 5), ('GCTAGTACCCA', 5), ('GTCCAATTTTC', 5), ('GCTTCAAGTAT', 4), ('AGCCTGACCTT', 4), ('GTGATTCCTTC', 4), ('ATAATAGCATT', 4), ('TCTAGCTGAGT', 3), ('TGATCTCCCAT', 3), ('CGCCTGCGCAC', 3), ('CTCCCCGACTA', 3), ('TAGTCTACATG', 3), ('GGTCGTGGGTC', 2), ('CCCACACCCCC', 2), ('GGGCTTCTGCT', 2), ('CCCACCACCCC', 2), ('TCTAATAGTAT', 2), ('ACTACAGTCCA', 2), ('CAGAGTAATAT', 2), ('CAGCAGAAGTG', 2), ('GGAATGGGAAG', 2), ('TTGACATTGCC', 2), ('TTCACCGTCCA', 2), ('CCAATCAGTGC', 2), ('TGTCGACAAAT', 2), ('GCTTCGAGGCT', 2), ('CGTCTGTTCAG', 2), ('CTCAAACTTAT', 2), ('GAACCACCACC', 2), ('CACGCCCCCCA', 1), ('GCATCACTAAA', 1), ('AGAAAAAATGT', 1), ('GCAACAGAGCC', 1), ('TCGCAAGGAAG', 1), ('GTTGGGTGGCA', 1), ('GATCTCAACTC', 1), ('AGCCCCTCCTT', 1), ('CCTCTCCCAAT', 1), ('CCGAGCTGAGT', 1), ('CTGAGCAGGAC', 1), ('GGGCCGTTAAA', 1), ('ATAACAGTGGG', 1), ('GGGGGGAATCA', 1), ('CACGAACTCAC', 1), ('GAGGCACAGAC', 1), ('AGATCCTTGCC', 1), ('TTGAGGGGGAG', 1), ('TTGCCTCACCC', 1), ('GGGCCCAGCAG', 1), ('GGGTGAATAAT', 1), ('TTGGGCCAACC', 1), ('CCCCAACAGGC', 1), ('GTGCGGGGTCG', 1), ('ATAAAAATAAC', 1), ('TTGCTAGGGAA', 1), ('GGTACTTGTGC', 1), ('CCCGATCCCAA', 1), ('GTACTTCATGA', 1), ('AACAGGAGAGA', 1), ('TGGTCCTCGAT', 1), ('TGCTCAGAGAT', 1), ('AAGTAAAAACT', 1), ('TGGACAGTGCC', 1), ('GAGGAGCTTGA', 1), ('GTTGATCGAAA', 1), ('CGCCACCCCGC', 1), ('TGCTTTTCATG', 1), ('CCCTCCCCGCC', 1), ('ATGAGCACCAC', 1), ('GGGAAACTTAA', 1), ('TCCCCCCACCC', 1), ('CACTCTTCGGT', 1), ('CGTCTAGGAGG', 1), ('TCTATTTGAAA', 1), ('GCAAAAACCCA', 1)]\n"
     ]
    }
   ],
   "source": [
    "barcodes = defaultdict(int)\n",
    "\n",
    "for index, row in df_cells.iterrows():\n",
    "    b0 = row[\"cell_barcode_0\"]\n",
    "    b1 = row[\"cell_barcode_1\"]\n",
    "    # barcodes[b0] += row[\"cell_barcode_count_0\"]\n",
    "    # barcodes[b1] += int(row[\"cell_barcode_count_1\"])\n",
    "    if b0 in barcode_set: # lots of messed up reads...\n",
    "        barcodes[b0] += row[\"cell_barcode_count_0\"]\n",
    "    if b1 in barcode_set:\n",
    "        barcodes[b1] += int(row[\"cell_barcode_count_1\"])\n",
    "\n",
    "print(sorted(barcodes.items(), key=lambda x: x[1], reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}